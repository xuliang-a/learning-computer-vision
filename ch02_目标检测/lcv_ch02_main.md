# 目录

* [Q1-目标检测的单步模型和两步模型是什么意思？](#Q1-目标检测的单步模型和两步模型是什么意思)

* [Q2-两步模型的发展过程是什么样的？](#Q2-两步模型的发展过程是什么样的)

  - [RCNN](#RCNN)

  - [Fast RCNN](#Fast-RCNN)

  - [Faster RCNN](#Faster-RCNN)

* [Q3-Fast RCNN的ROI是如何映射到特征图上的？](#Q3-Fast-RCNN的ROI是如何映射到特征图上的)

* [Q4-Fast RCNN的ROI-Pooling是什么？](#Q4-Fast-RCNN的ROI-Pooling是什么)

* [Q5-Faster RCNN的RPN网络是什么？](#Q5-Faster-RCNN的RPN网络是什么)

* [Q6-非极大值抑制处理的流程是什么？](#Q6-非极大值抑制处理的流程是什么)

* [Q7-单阶段检测算法的发展过程是什么样的？](#Q7-单阶段检测算法的发展过程是什么样的)

  - [YOLO](#YOLO)

  - [YOLOv2](#YOLOv2)

  - [YOLO9000](#YOLO9000)

  - [YOLOv3](#YOLOv3)

* [Q8-增强模型对小目标的检测效果有哪些方法？](#Q8-增强模型对小目标的检测效果有哪些方法)

* [中英文词汇](#中英文词汇)

# 目标检测

## Q1-目标检测的单步模型和两步模型是什么意思

单步模型是指没有独立地、显示地提取候选区域（Region Proposal，RP），直接由输入图像得到其中存在的目标的类别和位置信息的模型。

两步模型是有独立的、显示的候选区域的提取过程，即先在输入图像上筛选出一些可能存在物体的候选区域，然后针对每个候选区域，判断是否存在物体，若存在就给出物体的类别和修正信息。

**优缺点：** 一般来说，单步模型在计算效率上有优势，两步模型在检测精度上有优势。

对于单步模型和两步模型在**速度和精度上的差异**，学术界一般认为有如下原因：

（1）多数的单步模型是利用预设的锚框来捕捉可能存在于图像中各个位置的物体，单步模型会对数量庞大的锚框进行是否有物体及物体所述类别的密集分类，由于图像实际物体数目远小于锚框数目，所以正负样本极其不均衡，导致分类器效果不好。由于两步模型中，含有独立的候选区域提取步骤，在第一步中会筛选掉大部分不含有待检测物体的区域，即负样本，再传递给第二步进行分类和候选区域位置修正时，正负样本比例均衡。

（2）两步模型在候选区域提取过程中会对候选框的位置和大小进行修正，在第二阶段区域特征已被对齐，然后在第二阶段候选框会再次修正，所以带来了更高的精准度。单步模型输入特征未被对齐，质量较差，所以在分类和定位的精度较差。

（3）由于两步模型在第二步需要对每一个候选区域进行分类和位置回归，所以在候选区域数目非常大时，计算量与之成正比，所以存在计算量大，速度慢的问题。
	
摘自《百面深度学习》P234-236

- **Two stage目标检测算法**

    - 先进行区域生成（一个有可能包含待检物体的预选框），再通过卷积神经网络进行样本分类。

    - 任务：特征提取—>生成RP—>分类/定位回归。
    
    - 常见的有R-CNN、Fast R-CNN、Faster R-CNN。

- **One stage目标检测算法**

    - 不用RP，直接在网络中提取特征来预测物体分类和位置。

    - 任务：特征提取—>分类/定位回归
    
    - 常见的有OverFeat、SSD和YOLO系列模型

摘自《深度学习500问》

## Q2: 两步模型的发展过程是什么样的？

### RCNN	

RCNN是目标检测的奠基之作，RCNN是第一个将卷积神经网络用于目标检测的深度学习模型，具体来说我总结为三个步骤：

第一步，输入图像并选取提议区域（候选区域），对提议区域的选择可以使用选择性搜索（Selective Search）方法将输入图像中具有相似颜色直方图特征的区域进行递归合并，来提取1千到2千个提议区域；

第二步，提取特征，在选取提议区域之后，首先将每个区域首先进行缩放和裁剪，使区域能匹配卷积神经网络的输入维度，在缩放之后将区域送入卷积神经网络生成固定长度的特征，来提取特征；

第三步，分类和回归计算，对每一个提议区域的特征送入SVM分类器进行目标的分类，然后进一步将该类别的特征送入多层感知机进行目标坐标位置的回归修正；

![](https://github.com/scutan90/DeepLearning-500-questions/blob/master/ch08_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/img/ch8/8.2.1-1.png)

### Fast RCNN

由于RCNN需要对每一个提议区域进行特征提取计算即卷积计算，而这些提议区域很多都是高度重叠的，所以为了减少训练时间，Fast RCNN提出了改进方法。

第一步，输入图像并选取提议区域；

第二步，提取特征，将整幅输入图像作为卷积神经网络的输入，得到一幅特征图，和RCNN不同的是，RCNN将每个提议区域都送入一次卷积神经网络，而Fast RCNN将提议区域位置映射到了卷积神经网络的最后一层的特征图上，该方法节约了时间。由于接下来需要对每个不同尺寸提议区域对应的特征图送入多层感知机，而多层感知机的输入是固定的，所以提出了ROI Pooling层来将不同尺寸的特征下采样到相同尺寸，得到最后固定长度的特征。

第三步，对特征进行分类和回归。

其实Fast RCNN与SPPNet设计思路类似，SPPNet是空间金字塔池化而非ROI Pooling。

![](https://github.com/scutan90/DeepLearning-500-questions/blob/master/ch08_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/img/ch8/8.2.2-1.png)

### Faster RCNN

该网络从提议区域的生成速度，来对网络的性能进行提高，该网络提出了一个新颖的RPN网络来改进耗时的选择性搜索。

第一步，输入图像提取特征图，和Fast RCNN相同，Faster RCNN对输入图像做一次卷积计算得到一幅特征图。

第二步，将特征图作为新颖的RPN网络（Region Proposal Networks）的输入来提取提议区域。接着和Fast RCNN一样将提议区域和特征图进行映射然后送入ROI Pooling，得到固定尺寸的特征。

第三步，对特征进行分类和回归。

![](https://github.com/scutan90/DeepLearning-500-questions/blob/master/ch08_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/img/ch8/8.2.3-1.png)
![](https://github.com/scutan90/DeepLearning-500-questions/blob/master/ch08_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/img/ch8/8.2.3-2.png)

## Q3-Fast RCNN的ROI是如何映射到特征图上的

ROI是Region of Interest的简写，指的是由选择性搜索提取的候选区域。

ROI映射的目标是原图ROI区域的中心点尽量接近特征图对应区域的中心点。

关于ROI映射我看到了如下映射方法：

- 把在输入图像上的ROI各个坐标除以“输入图片与Feature Map的大小的比值”，得到了feature map上的box坐标。（摘自《深度学习500问》）

  例子,输入图像 $600 \times 800$, 特征图 $38 \times 50$，原图的ROI左上角坐标(30,40)、左下角坐标(200,400)，
  
  那么有在特征图上的左上角坐标 $( 30 \times (38/600), 40 \times (50/800) )$和左下角坐标 $( 200 \times (38/600), 400 \times (50/800) )$，四舍五入后得到(2,3)和(13, 25)

- SPPNet的ROI映射

在SPPNet中，假设(x’,y’)表示特征图上坐标点，(x,y)表示该坐标点在原始输入图像上的对应点。则有结论 (x,y)=(S * x’,S * y’) 其中S代表所有卷积层和池化层的stride乘积

为了处理有小数的情况，同时左上角点和右下角点都向图像内侧近似(左上角要向右下偏移，右下角要想要向左上偏移)，所以左上角加一 右下角减一 同时为了减小这种近似产生的误差 所以左上角向下取整 右下角向上取整。

最后，左上角点 x’= ⌊x/S⌋+1 右下角点 x’=⌈x/S⌉-1

该推导用到的计算公式：

若卷积核边长为k，填充是p，步长是s，则有如下坐标计算，

- 对于卷积和池化层，$ p_i = s \times p_{i+1} + ((k-1)/2-p)$

- 对于激活层，$ p_i = p_{i+1}$

一个计算卷积后图像中坐标的例子，

![一个计算卷积后图像中坐标的例子](https://pic2.zhimg.com/v2-c1ce5a16dbd75553be1a9ea8921f3c35_r.jpg)

为了简化计算，可以将$$((k-1)/2-p)$$化简，将每一个卷积层和池化层的填充设置为小于等于当前层滤波器尺寸一半的最大整数（就是取下限），即 $p=\lfloor k_i / 2 \rfloor$。

那么，就有 $ p_i = S_i \times p_{i+1} + ((k_i-1)/2 - \lfloor k_i / 2 \rfloor)$

- 当 $k_i$为奇数时, $((k_i-1)/2 - \lfloor k_i / 2 \rfloor) = 0$，有 $p_i = S_i \times p_{i+1} $

- 当 $k_i$为偶数时，$((k_i-1)/2 - \lfloor k_i / 2 \rfloor) = -1/2$，有 $p_i = S_i \times p_{i+1} - 1/2$

因为 $p_i$是坐标值，不可能取到小数，所以可以得到 $p_i = S_i \times p_{i+1} $，公式这样就得到了化简， $p_i$ 只跟 $p_{i+1}$和步长有关。

将公式一层一层进行级联，得到 $p_0 = S \times p_{i+1}$, 其中 $S=\prod_0^i s_i$;

对于特征图上的(x’,y’)，则有结论该坐标点在原始输入图像上的对应点(x,y)=(S * x’,S * y’) 其中S代表所有卷积层和池化层的stride乘积。

然后根据前面说的左上角向右下角偏移，右下角向左上角偏移再调整一下得到左上角点 $(x' = \lfloor x/S \rfloor + 1, y' = \lfloor y/S \rfloor + 1)$，右下角点$(x' = \lceil x/S \rceil - 1, y' = \lceil y/S \rceil - 1)$


## Q4-Fast RCNN的ROI Pooling是什么

ROI pooling层是pooling层的一种，由于是针对ROI进行的池化操作，所以称为ROI Pooling

第一步，根据输入的图像将提议区域ROI映射到特征图上对应的位置；

第二步，将映射后的ROI区域划分为与输出维度相同的切片；

第三步，对每个切片进行最大池化操作。

这样就可以从不同尺寸的ROI提议区域得到固定大小的特征图，该ROI Pooling的结果特征图不依赖ROI的尺寸。

例如：输入图像经过一系列卷积和池化操作缩小32倍后的输出特征图的尺寸为：$8 \times 8$，提议区域ROI对应于输入图像的左上角和右下角坐标分别为（0,100）和（198,224），规定输出大小为：$2 \times 2$。

第一步，进行ROI映射，可能会产生量化误差。

映射到特征图后ROI左上角坐标:（0,100/32），将坐标向下取整，变为（0,3）

映射到特征图后ROI右下角坐标（198/32,224/32），将坐标向下取整，变为（6,7）

第二步，将ROI划分成$2 \times 2$的区域切片，可能会产生量化误差。

映射到特征图后ROI的宽为7，划分2份后，每个区域的宽为：7/2 = 3.5，左半部分的宽取3，右半部分的宽取4

映射到特征图后ROI的长为5，划分2份后，每个区域的长为：5/2 = 2.5，上半部分的长取2，下半部分的长取3

第三步，对划分后的区域进行最大池化操作。

![](https://github.com/scutan90/DeepLearning-500-questions/blob/master/ch08_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/img/ch8/8.1.11.gif)

## Q5-Faster RCNN的RPN网络是什么

RPN网络是候选区域网络，用来替代选择性搜索来生成ROI，这个新颖的RPN网络实质上是一种基于神经网络的的二分类和边界框回归模型；

![RPN](https://img-blog.csdn.net/20180120181848383?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGFucmFuMg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

1. 以特征图每个单元为中心，生成k个不同大小和宽高比的锚框并标注它们，一共会产生 $k\times w\times h $个锚框。

![](https://github.com/scutan90/DeepLearning-500-questions/blob/master/ch08_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/img/ch8/8.2.3-4.png)

2. 对于一个$ w\times h$ 的特征图，使用一共填充为2，步长1的 $3\times 3$ 卷积层变换卷积神经网络的输出，并将输出通道数记为 c=256 。这样，卷积神经网络为图像抽取的特征图中的每个单元均得到一个长度为 256 的新特征,即得到一个$ w\times h \times 256$的特征。

3. 用锚框中心单元长度为 c= 256 的特征分别在分类层得到2k个得分，用于预测该锚框的二元类别（含目标还是背景的概率），在回归层得到4k个坐标偏移量，用于边界框的回归，该分类层和回归层都可以使用 $1 \times 1$卷积来实现全连接层的所需输出的功能。

4. 最后使用非极大值抑制，从预测类别为目标的预测边界框中移除相似的结果。最终输出的预测边界框即兴趣区域池化层所需要的提议区域。

参考https://blog.csdn.net/lanran2/article/details/54376126

## Q6-非极大值抑制处理的流程是什么

目的：忽略相互间高度重叠的锚框（即：将Iou重叠率大于0.7框，比较分类的得分，保留分类的得分大的框）

![](https://images2017.cnblogs.com/blog/606386/201708/606386-20170826153025589-977347485.png)

**非极大值抑制的方法：**

例如：先假设有6个矩形框，根据分类器的类别分类概率(即：为背景或目标的得分)做排序，假设从小到大属于车辆的概率 分别为A、B、C、D、E、F。

1)从最大概率矩形框F开始，分别判断A~E与F的重叠度IOU是否大于某个设定的阈值;

2)假设B、D与F的重叠度超过阈值，那么就扔掉B、D；并标记第一个矩形框F，是我们保留下来的。

3)从剩下的矩形框A、C、E中，选择概率最大的E，然后判断E与A、C的重叠度，重叠度大于一定的阈值，那么就扔掉；并标记E是我们保留下来的第二个矩形框。

就这样一直重复，找到所有被保留下来的矩形框。

**交并比**（Intersection-over-Union，IoU）

它是目标检测中使用的一个概念，是产生的候选框（candidate bound）与原标记框（ground truth bound）的交叠率，即它们的交集与并集的比值。

![](https://img-blog.csdnimg.cn/20181102130324332.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMwNjM4ODMx,size_16,color_FFFFFF,t_70)

对于非极大值抑制算法来说，IoU指的是两个候选框之间的交叠率。

## Q7-单阶段检测算法的发展过程是什么样的

### YOLO

### YOLOv2

### YOLO9000

### YOLOv3

## Q8-增强模型对小目标的检测效果有哪些方法

针对于小目标检测，可以从一下几个角度入手：

- 在模型的设计方面，可以采用特征金字塔来增强网络对多尺度尤其是小尺度特征的感知和处理能力；尽可能提升网络的感受野，使得网络能够更多地利用上下文信息来增强检测效果；同时减少网络总的下采样比例，使最后用于检测的特征分辨率更高。

- 在训练方面，可以提高小物体样本在总体样本中的比例；也可以利用数据增强手段，将图像缩小以生成小物体样本。

- 在计算量允许的范围内，可以尝试使用更大的输入图像尺寸。

摘自《百面深度学习》P240

# 中英文词汇

候选区域 提议区域（Region Proposal，RP）

选择性搜索（Selective Search）


# 卷积神经网络

## Q1：卷积神经网络是什么和全连接层有什么区别？
在卷积神经网络出现之前，MLP多层感知机是比较常见神经网络。MLP相邻层节点通常是全连接的，也就是输入层的每个节点会与输出层每个节点相连接。与MLP不同，卷积神经网络的主要组成部分是卷积层，每个卷积层通过特定数目的卷积核与输入图像进行扫描和计算，由于卷积核的尺寸一般是要小于输入图像的尺寸，所以卷积层输出的每个节点只与输入层的部分节点相连接，称为局部连接，该特点与MLP的全连接不同。另外卷积神经网络还有另一个特征，权值共享，具体来说卷积层输出的每个节点，与输入层所连接的权值是一样的，也就是都是卷积核的参数。

参考《百面机器学习》P4-7

一个多输入通道的卷积计算图例

![](https://zh.d2l.ai/_images/conv_multi_in.svg)

摘自《动手学深度学习》

## Q2：卷积层输出尺寸和感受野怎么计算？

卷积层输出的尺寸由卷积核尺寸（$ k\times k $）、卷积核滑动步长(stride)和对原图边缘所填充(padding)的尺寸所决定。

若没有步长s和填充p，有

$ \mbox{输出边长} = \mbox{输入边长}  - k + 1 $

若宽或高的两侧一共填充p(注意是一共填充还是分别填充)，没有步长s，有

$ \mbox{输出边长}  = \mbox{输入边长} - k + p + 1 $

若宽或高的两侧分别填充p，步长s，有

$ \mbox{输出边长} = (\mbox{输入边长}- k + 2p + s) / s = (\mbox{输入边长} - k + 2p)/s + 1 $，若是小数则取下限

若输入图像为$3\times 3$, 核为$2\times 2$,宽或高的两侧分别填充1，在高和宽上步幅分别为3和2，有

$ {(3 - 2 + 2)/3 + 1 }\times {(3 - 2 + 2)/2 + 1} = 2 \times 2

该计算的图例

![](https://zh.d2l.ai/_images/conv_stride.svg)

参考《动手学深度学习》

感受野，也就是卷积结果对应输入的区域尺寸，其实就是反过来求解卷积层的输入尺寸

$ \mbox{卷积层的输入尺寸（感受野）} = (\mbox{卷积层输出尺寸}-1)\times s + k - 2p  $

根据这个公式可以从后向前计算感受野，向前一层一层计算就可以计算到在原始图片上对应的感受野了。

## Q3：卷积层参数数量和计算量怎么计算？

## Q4：卷积层和池化层有什么区别？

## Q5：有哪些池化方法？

## Q6：怎么组成一个基本完整的卷积神经网络？

## Q7：一个1*1的卷积层有什么作用？

## Q8：有哪些变种卷积？

## Q9：用于图像分类的卷积神经网络发展过程是怎样的？

## Q10：用于分类的卷积神经网络最后几层一般是什么层？



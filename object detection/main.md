
# 目标检测
## Q1: 目标检测的单步模型和两步模型是什么意思？

单步模型是指没有独立地、显示地提取候选区域，直接由输入图像得到其中存在的目标的类别和位置信息的模型，常见的有OverFeat、SSD和YOLO系列模型。

两步模型是有独立的、显示的候选区域的提取过程，即先在输入图像上筛选出一些可能存在物体的候选区域，然后针对每个候选区域，判断是否存在物体，若存在就给出物体的类别和修正信息，常见的模型有**R-CNN、SPPNet、Fast R-CNN、Faster R-CNN、Mask R-CNN**。

**优缺点：** 一般来说，单步模型在计算效率上有优势，两步模型在检测精度上有优势。

对于单步模型和两步模型在**速度和精度上的差异**，学术界一般认为有如下原因：

（1）多数的单步模型是利用预设的锚框来捕捉可能存在于图像中各个位置的物体，单步模型会对数量庞大的锚框进行是否有物体及物体所述类别的密集分类，由于图像实际物体数目远小于锚框数目，所以正负样本极其不均衡，导致分类器效果不好。由于两步模型中，含有独立的候选区域提取步骤，在第一步中会筛选掉大部分不含有待检测物体的区域，即负样本，再传递给第二步进行分类和候选区域位置修正时，正负样本比例均衡。

（2）两步模型在候选区域提取过程中会对候选框的位置和大小进行修正，在第二阶段区域特征已被对齐，然后在第二阶段候选框会再次修正，所以带来了更高的精准度。单步模型输入特征未被对齐，质量较差，所以在分类和定位的精度较差。

（3）由于两步模型在第二步需要对每一个候选区域进行分类和位置回归，所以在候选区域数目非常大时，计算量与之成正比，所以存在计算量大，速度慢的问题。
	
摘自《百面深度学习》P234-236

- **Two stage目标检测算法**

    - 先进行区域生成（region proposal，RP）（一个有可能包含待检物体的预选框），再通过卷积神经网络进行样本分类。

    - 任务：特征提取—>生成RP—>分类/定位回归。

- **One stage目标检测算法**

    - 不用RP，直接在网络中提取特征来预测物体分类和位置。

    - 任务：特征提取—>分类/定位回归

摘自《深度学习500问》

## Q2: 两步模型的发展过程是什么样的？

### RCNN	
RCNN是目标检测的奠基之作，RCNN是第一个将卷积神经网络用于目标检测的深度学习模型，具体来说我总结为三个步骤：

第一步，输入图像并选取提议区域（候选区域），对提议区域的选择可以使用选择性搜索方法将输入图像中具有相似颜色直方图特征的区域进行递归合并，来提取1千到2千个提议区域；

第二步，提取特征，在选取提议区域之后，首先将每个区域首先进行缩放和裁剪，使区域能匹配卷积神经网络的输入维度，在缩放之后将区域送入卷积神经网络生成固定长度的特征，来提取特征；

第三步，分类和回归计算，对每一个提议区域的特征送入SVM分类器进行目标的分类，然后进一步将该类别的特征送入多层感知机进行目标坐标位置的回归修正；

![](https://github.com/scutan90/DeepLearning-500-questions/blob/master/ch08_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/img/ch8/8.2.1-1.png)

### Fast RCNN
由于RCNN需要对每一个提议区域进行特征提取计算即卷积计算，而这些提议区域很多都是高度重叠的，所以为了减少训练时间，Fast RCNN提出了改进方法。

第一步，输入图像并选取提议区域；

第二步，提取特征，将整幅输入图像作为卷积神经网络的输入，得到一幅特征图，和RCNN不同的是，RCNN将每个提议区域都送入一次卷积神经网络，而Fast RCNN将提议区域位置映射到了卷积神经网络的最后一层的特征图上，该方法节约了时间。由于接下来需要对每个不同尺寸提议区域对应的特征图送入多层感知机，而多层感知机的输入是固定的，所以提出了ROI-pooling层来将不同尺寸的特征下采样到相同尺寸，得到最后固定长度的特征。

第三步，对特征进行分类和回归。

其实Fast RCNN与SPPNet设计思路类似，SPPNet是空间金字塔池化而非ROI pooling。

![](https://github.com/scutan90/DeepLearning-500-questions/blob/master/ch08_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/img/ch8/8.2.2-1.png)

### Faster RCNN
该网络从提议区域的生成速度，来对网络的性能进行提高，该网络提出了一个新颖的RPN网络来改进耗时的选择性搜索。

第一步，输入图像提取特征图，和Fast RCNN相同，Faster RCNN对输入图像做一次卷积计算得到一幅特征图。

第二步，将特征图作为新颖的RPN网络（Region Proposal Networks）的输入来提取提议区域。接着和Fast RCNN一样将提议区域和特征图进行映射然后送入ROI-pooling，得到固定尺寸的特征。

第三步，对特征进行分类和回归。

![](https://github.com/scutan90/DeepLearning-500-questions/blob/master/ch08_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/img/ch8/8.2.3-1.png)
![](https://github.com/scutan90/DeepLearning-500-questions/blob/master/ch08_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/img/ch8/8.2.3-2.png)

## Q3：特征图feature map和提议区域ROI是怎么映射的？


ROI映射的目标是原图ROI区域的中心点尽量接近特征图对应区域的中心点。

我看到了如下映射方法：

（1） 把各个坐标除以“输入图片与feature map的大小的比值”，得到了feature map上的box坐标。（摘自《深度学习500问》）

（2） SPPNet的ROI映射

在SPP-net中，假设（x’,y’）表示特征图上坐标点，（x,y）表示该坐标点在原始输入图像上的对应点。则有结论 （x,y）=(S * x’,S * y’) 其中S代表所有卷积层和池化层的stride 乘积

为了处理有小数的情况，同时左上角点和右下角点都向图像内侧近似(左上角要向右下偏移，右下角要想要向左上偏移)，所以左上角加一 右下角减一 同时为了减小这种近似产生的误差 所以左上角向下取整 右下角向上取整

最后，左上角点 x’= ⌊x/S ⌋+1 右下角点 x’=⌈x/S⌉-1

该推导用到的计算公式：

首先要说明一下卷积输出尺寸的计算，卷积核边长为k，填充是p，步长是s，则有

卷积层输出尺寸 = (卷积层输入尺寸 – k + 2p)/s + 1

那么有感受野，也就是卷积结果对应输入的区域大小的计算方法

卷积层的输入尺寸（感受野） = (卷积层输出尺寸-1)*s + k -2p

根据这个公式可以从后向前计算感受野，向前一层一层计算就可以计算到在原始图片上对应的感受野了。

感受野坐标计算

$$
p_i = s * p_{i+1} + ((k-1)/2-p)
$$

坐标计算例子

![](https://pic2.zhimg.com/v2-c1ce5a16dbd75553be1a9ea8921f3c35_r.jpg)

为了简化计算，可以将$$(k-1)/2-p)$$化简，将卷积层和池化层的填充设置为小于等于滤波器尺寸一半的最大整数

那么，

![](https://img-blog.csdn.net/20181011190140223?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2E5NDA5MDI5NDA5MDI=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)


## Q4：ROI pooling是什么？
ROI pooling层是pooling层的一种，由于是针对ROI进行的池化操作，所以称为ROI pooling

第一步，根据输入的图像将提议区域映射到特征图对应的位置。

第二步，将映射后的区域划分为相同大小的尺寸的sections

第三步，对每个sections进行最大池化操作

这样就可以从不同尺寸的ROI提议区域得到固定大小的特征图。

![](https://github.com/scutan90/DeepLearning-500-questions/blob/master/ch08_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/img/ch8/8.1.11.gif)

